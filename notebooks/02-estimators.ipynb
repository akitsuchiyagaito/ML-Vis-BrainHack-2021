{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Core concepts\n",
    "\n",
    "In this notebook, we will review:\n",
    "- Estimators in scikit-learn, what are they and some of their functions.\n",
    "- How estimators can be supervised models that perform classification or regression tasks, as well as unsupervised models.\n",
    "- Common metrics used to evaluate the estimator performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators\n",
    "\n",
    "In scikit-learn an [estimator](https://scikit-learn.org/stable/tutorial/statistical_inference/settings.html#estimators-objects) is a Python object that learns from data.\n",
    "\n",
    "(...) Estimators come with associated functions. We will review some of these in this tutorial.\n",
    "\n",
    "Most importantly, in scikit-learn both supervised and unsupervised models are created using estimator objects. Let's review each of them in turn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised models\n",
    "\n",
    "(...) Explain supervised models\n",
    "\n",
    "(...) They divide into regression and classification models. (difference between regression and classification)\n",
    "\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "We will make a quick recap of linear regression models, but we will not provide a detailed description. Be sure to read one of our additional resources if you want to refresh your knowledge or dig deeper into the topic.\n",
    "\n",
    "As a machine learning model, linear regression predicts the values of a continuous variable from a linear combination of the values in one or more features.\n",
    "\n",
    "For example, if we had a dataset $X$ contaning the values of features $x1$ and $x2$, the value $\\hat{y}$ predicted by linear regression could be expressed as:\n",
    "\n",
    "$$\\hat{y} = ax1 + bx2 + c$$\n",
    "\n",
    "> where $a$, $b$ and $c$ are the parameters the model learns from the data to make the predictions\n",
    "\n",
    "- !! Add vector notation\n",
    "\n",
    "- !! Explain training and loss\n",
    "     - Supervised approach --> The model learns the parameters that minimize the distance between the predictve value and the real value\n",
    "\n",
    "\n",
    "Let's now see how we can fit a linear regression model using scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, we can easily create a fake dataset for fitting a linear regression model using the `make_regression` method (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression)). \n",
    "\n",
    "Let's create one dataset with 400 samples and 100 features. We will also define 20 of these features as informative, and add some gaussian noise to the data to make the task harder for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(\n",
    "    n_samples=400, n_features=100, n_informative=20, noise=10, random_state=0\n",
    ")\n",
    "print(f\"Shape of dataset: {np.shape(X)}\")\n",
    "print(f\"Shape of targets: {np.shape(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's a regression problem, let's make sure the target of our model is a continuous variable. Let's print the first ten values of `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a linear regression estimator using `LinearRegression` (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression#sklearn.linear_model.LinearRegression))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator objects contain certain parameters that define how they will behave when learning the data, as well as their outputs. Let's inspect the parameters of `reg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters can be changed by modifying their corresponding attributes when calling the estimator, or afterwards in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.set_params(**{\"normalize\": True})\n",
    "vars(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Once the object has been created, we can now train the model using our data. For this we need to call the `fit` method, and pass our data (`X`) and target (`y`) as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression model\n",
    "reg = reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the attributes of `reg` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars(reg).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reg` now contains new attributes, which are refered to as _estimated parameters_, because they have been learned from the data. In scikit-learn, these are indexed by an underscore (`_`) at the end. \n",
    "\n",
    "For example, we can now access the coefficients learned by our linear model. We should have as many coefficients as features in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of coefficients: {reg.coef_.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also print the values of some of them, and the value of the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = reg.coef_\n",
    "intercept = reg.intercept_\n",
    "\n",
    "print(f\"Model coefficients (first 10):\\n {coefs[:10]} \\n\")\n",
    "print(f\"Model intercept: \\n {intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with the model\n",
    "\n",
    "Now that our model is fitted, we can use it to make predictions. In scikit-learn, this is achieved by calling the method `predict`. \n",
    "\n",
    "Let's predict the values of `X` using our fitted model, and visually compare them to their real values for the first ten samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Predict labels with trained model\n",
    "y_pred = reg.predict(X)\n",
    "\n",
    "# Create dataframe for printing the predictions\n",
    "df = pd.DataFrame({\"y_pred\": y_pred[:10], \"y_real\": y[:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the model\n",
    "\n",
    "We can use these predictions to evaluate the performance of the model. That is, estimate how wrong the model is by quantifing the difference between the predicted values and the real ones. \n",
    "\n",
    "In scikit-learn we can evaluate this performance using the method `score`. Let's use this method to evaluate how well our model predicts the targets of our fake dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = reg.score(X, y)\n",
    "print(f\"Linear model R2: {np.round(score,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, linear models are evaluated by calculating $R^2$.\n",
    "\n",
    "(...) Explain $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other scoring metrics for regression problems besides $R^2$. Check the module [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) for an overview of the alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✍️ Exercise\n",
    "\n",
    "Suppose we already have `X` and `y` defined and we want perform linear regression on our data. Why would the following code fail?\n",
    "\n",
    "```\n",
    "reg = LinearRegression()\n",
    "reg.score(X, y)\n",
    "```\n",
    "\n",
    "Can you fix it? Click the three dots to reveal the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "The code did not fit the model! For it to work it should read:\n",
    "\n",
    "```\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, y)\n",
    "reg.score(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "As mentioned, classification models are also estimators. One of the most popular classification models is __logistic regression__\n",
    "\n",
    "(...) Explain logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a fake dataset ready for classification using the `make_classification` method (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=400, n_features=100, n_informative=20, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `y` should now be a categorical variable. Let's print 10 samples of it to make sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a `LogisticRegression` estimator (read the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)) and fit it to our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create model\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Fit model\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✍️ Exercise\n",
    "\n",
    "Do you remember how to inspect the coefficients and intercept of the model? Try it below, and press the three dots to check your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Answer\n",
    "coefs = clf.coef_\n",
    "intercept = clf.intercept_\n",
    "\n",
    "print(f\"Coefficients:\\n{coefs}\\n\")\n",
    "print(f\"Intercept:{intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compare the model predictions of the first 10 samples of `X` to their real labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict labels with trained model\n",
    "y_pred = clf.predict(X[:10])\n",
    "y_real = y[:10]\n",
    "\n",
    "# Create dataframe for printing the predictions\n",
    "df = pd.DataFrame({\"y_pred\": y_pred, \"y_real\": y_real})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic predictions\n",
    "\n",
    "Logistic Regression is a [probabilistic classifier](https://en.wikipedia.org/wiki/Probabilistic_classification), meaning it predicts a probability distribution over the classes.\n",
    "\n",
    "In _scikit-learn_ we can inspect the probabilities assigned to each class in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the probability of each class\n",
    "y_pred_proba = clf.predict_proba(X[:10])\n",
    "\n",
    "# Create dataframe for printing the predictions\n",
    "df = pd.DataFrame(y_pred_proba, columns=[\"class 0\", \"class 1\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the predictions made by `LogisticRegression` when calling `score` are evaluated by computing the __mean accuracy__ of the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score predictions\n",
    "score = clf.score(X, y)\n",
    "print(f\"Mean accuracy: {np.round(score, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides scoring the model, in classification problems, it is very common to plot the __confusion matrix__ of the predictions.\n",
    "\n",
    "(...) Explain what is a confusion matrix. Paste picture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now learn how to plot the confusion matrix of the predictions of some model in scikit-learn. \n",
    "\n",
    "We will first create an imbalanced classification dataset, meaning one containing more samples from one of the classes than the other. This dataset will make the example more interesting. We can create the imbalance by setting the parameter `weights` of `make_classification`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=400, n_features=100, n_informative=20, \n",
    "    weights=[0.8, 0.2], random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create and fit a logistic regression model, and use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit model\n",
    "clf = LogisticRegression().fit(X, y)\n",
    "\n",
    "# Use model to make predictions\n",
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the predicted labels, we can now run this computation using the function `confusion_matrix` (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)), and display it using `ConfusionMatrixDisplay` (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "conf_matrix = confusion_matrix(y, y_pred, labels=clf.classes_)\n",
    "cm_display = ConfusionMatrixDisplay(conf_matrix).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(...) Explain output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✍️ Exercise\n",
    "\n",
    "There are other ways of scoring your model besides computing its mean accuracy. Read the documentation about scoring the [precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score) and the [recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score) of a model. \n",
    "\n",
    "Can you implement these score functions yourself? Try them below, and press the three dots to reveal the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Answer\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y, y_pred)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y, y_pred)\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "\n",
    "Unsupervised models are also estimators in scikit-learn, since they also learn from data\n",
    "\n",
    "- (...) recap of unsupervised learning:\n",
    "    - the goal is to find interesting or useful structure in the data\n",
    "    - we don't have the ground truth\n",
    "\n",
    "Clustering methods are unsupervised models. \n",
    "    - (...) explain clustering methods\n",
    "\n",
    "One popular clustering method is k-means\n",
    "    - (...) Explain how k-means work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a dataset suitable for clustering using `make_blobs` (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs)) which generates Gaussian shaped blobs, and visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Create fake dataset\n",
    "X, y = make_blobs(\n",
    "    n_samples=400, n_features=2, random_state=0, cluster_std=1\n",
    ")\n",
    "\n",
    "# Plot dataset\n",
    "sns.scatterplot(\n",
    "    x=X[:, 0], y=X[:, 1], hue=y,\n",
    "    marker='o', s=25, edgecolor='k', legend=True\n",
    ").set_title(\"Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform k-means clustering by calling `KMeans` in scikit-learn (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)). We will pre-define $k$ to be equal to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create model\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "\n",
    "# Fit model\n",
    "kmeans = kmeans.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is an unsupervised method and there is no real truth labels, we cannot compute the accuracy of the fitted model. But we can compute the average distance of the labeled example to the center of their assigned cluster using the `score` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average distance\n",
    "score = kmeans.score(X, y)\n",
    "print(f\"Average distance: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to read more about the meaning behind the returned value, read [this answer](https://stackoverflow.com/questions/32370543/understanding-score-returned-by-scikit-learn-kmeans) on stackoverflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More importantly, we can now use our fitted model to predict to which cluster the observations belong to. Let's predict the assignment of the first 10 observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict cluster label\n",
    "y_pred = kmeans.predict(X)\n",
    "print(f\"Predicted labels (first 10): {y_pred[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a scatterplot to inspect the predicted labels from the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predicted labels\n",
    "sns.scatterplot(\n",
    "    x=X[:, 0], y=X[:, 1], hue=y_pred,\n",
    "    marker='o', s=25, edgecolor='k', legend=False\n",
    ").set_title(\"Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the same number of predicted labels as the number of $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✍️ Exercise \n",
    "\n",
    "Can you create a `KMeans` model specifying the correct number of clusters (`k=3`) and plot its predictions? Try it below and press the three dots to see the solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Answer\n",
    "# Create model\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "\n",
    "# Fit model\n",
    "kmeans = kmeans.fit(X, y)\n",
    "\n",
    "# Predict labels\n",
    "y_pred = kmeans.predict(X)\n",
    "\n",
    "# Plot predicted labels\n",
    "sns.scatterplot(\n",
    "    x=X[:, 0], y=X[:, 1], hue=y_pred,\n",
    "    marker='o', s=25, edgecolor='k', legend=False\n",
    ").set_title(\"Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ✏️ Check your knowledge\n",
    "\n",
    "Load the ABIDE 2 dataset and:\n",
    "\n",
    "1. Use logistic regression to predict \"group\" from the features encoding brain data.\n",
    "    - How accurate is the model?\n",
    "    - Compute the confusion matrix and inspect the proportion of false positives and false negatives.\n",
    "2. Select two features encoding brain data, run a clustering analyses and plot the predicted labels as shown in this example. Compare it with a similar plot showing the true group labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional reading\n",
    "\n",
    "- [Choosing the right estimator](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html): A useful map to decide which estimator is best given your dataset and learning goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
