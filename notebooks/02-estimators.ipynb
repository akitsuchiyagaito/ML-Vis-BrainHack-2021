{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 - Core concepts\n",
    "\n",
    "In this notebook, we will review:\n",
    "- Estimators in scikit-learn, what are them and some of their methods.\n",
    "- How estimators can be supervised models that perform classification or regression tasks, as well as unsupervised models.\n",
    "- Common metrics used to evaluate the estimator performance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators\n",
    "\n",
    "In scikit-learn an [estimator](https://scikit-learn.org/stable/tutorial/statistical_inference/settings.html#estimators-objects) is a Python object that learns from data.\n",
    "\n",
    "(...) An estimator comes with some associated methods. We will review these throughout this tutorial.\n",
    "\n",
    "Most importantly, in scikit-learn both supervised and unsupervised models are created using estimator objects. Let's review each of them in turn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised models\n",
    "\n",
    "(...) Explain supervised models\n",
    "\n",
    "(...) They divide into regression and classification models. (difference between regression and classification)\n",
    "\n",
    "\n",
    "## Linear Regression\n",
    "\n",
    "We will make a quick recap of linear regression models, but we will not provide a detailed description. Be sure to read one of our additional resources if you want to refresh your knowledge or dig deeper into the topic.\n",
    "\n",
    "As a machine learning model, linear regression predicts the values of a continuous variable from a linear combination of the values in one or more features.\n",
    "\n",
    "For example, if we had a dataset $X$ contaning the values of features $x1$ and $x2$, the value $\\hat{y}$ predicted by linear regression could be expressed as:\n",
    "\n",
    "$$\\hat{y} = ax1 + bx2 + c$$\n",
    "\n",
    "> where $a$, $b$ and $c$ are the parameters the model learns from the data to make the predictions\n",
    "\n",
    "- !! Add vector notation\n",
    "\n",
    "- !! Explain training and loss\n",
    "     - Supervised approach --> The model learns the parameters that minimize the distance between the predictve value and the real value\n",
    "\n",
    "\n",
    "Let's now see how we can fit a linear regression model using scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, we can easily create a fake dataset for fitting a linear regression model using the `make_regression` method (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html#sklearn.datasets.make_regression)). \n",
    "\n",
    "Let's create one dataset with 400 samples and 100 features. We will also define 20 of these features as informative, and add some gaussian noise to the data to make the task harder for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (400, 100)\n",
      "Shape of targets: (400,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(\n",
    "    n_samples=400, n_features=100, n_informative=20, noise=10, random_state=0\n",
    ")\n",
    "print(f\"Shape of dataset: {np.shape(X)}\")\n",
    "print(f\"Shape of targets: {np.shape(y)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's a regression problem, let's make sure the target of our model is a continuous variable. Let's print the first ten values of `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-258.45661829 -357.87561738  108.00450947   -8.40675451 -226.74854238\n",
      "  -38.23202934   18.14753729 -821.27365083  320.76896452  145.63900011]\n"
     ]
    }
   ],
   "source": [
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a linear regression estimator using `LinearRegression` (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html?highlight=linear%20regression#sklearn.linear_model.LinearRegression))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimator objects contain certain parameters that define how they will behave when learning the data, as well as their outputs. Let's inspect the parameters of `reg`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True,\n",
       " 'normalize': False,\n",
       " 'copy_X': True,\n",
       " 'n_jobs': None,\n",
       " 'positive': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These parameters can be changed by modifying their corresponding attributes when calling the estimator, or afterwards in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_intercept': True,\n",
       " 'normalize': True,\n",
       " 'copy_X': True,\n",
       " 'n_jobs': None,\n",
       " 'positive': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.set_params(**{\"normalize\": True})\n",
    "vars(reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model\n",
    "\n",
    "Once the object has been created, we can now train the model using our data. For this we need to call the `fit` method, and pass our data (`X`) and target (`y`) as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression model\n",
    "reg = reg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the attributes of `reg` again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fit_intercept', 'normalize', 'copy_X', 'n_jobs', 'positive', 'n_features_in_', 'coef_', '_residues', 'rank_', 'singular_', 'intercept_'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(reg).keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reg` now contains new attributes, which are refered to as _estimated parameters_, because they have been learned from the data. In scikit-learn, these are indexed by an underscore (`_`) at the end. \n",
    "\n",
    "For example, we can now access the coefficients learned by our linear model. We should have as many coefficients as features in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of coefficients: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of coefficients: {reg.coef_.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also print the values of some of them, and the value of the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients (first 10):\n",
      " [-1.13225733 -0.37761699 -0.55009782  0.11689833 -0.3783587   0.28209964\n",
      " -0.11756948 96.29011361 -1.00224858 81.99109074] \n",
      "\n",
      "Model intercept: \n",
      " -0.49212396559274585\n"
     ]
    }
   ],
   "source": [
    "coefs = reg.coef_\n",
    "intercept = reg.intercept_\n",
    "\n",
    "print(f\"Model coefficients (first 10):\\n {coefs[:10]} \\n\")\n",
    "print(f\"Model intercept: \\n {intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions with the model\n",
    "\n",
    "Now that our model is fitted, we can use it to make predictions. In scikit-learn, this is achieved by calling the method `predict`. \n",
    "\n",
    "Let's predict the values of `X` using our fitted model, and visually compare them to their real values for the first ten samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-269.240138</td>\n",
       "      <td>-258.456618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-349.576199</td>\n",
       "      <td>-357.875617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106.003478</td>\n",
       "      <td>108.004509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-31.193701</td>\n",
       "      <td>-8.406755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-240.331344</td>\n",
       "      <td>-226.748542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-44.646219</td>\n",
       "      <td>-38.232029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.240374</td>\n",
       "      <td>18.147537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-819.226112</td>\n",
       "      <td>-821.273651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>322.174534</td>\n",
       "      <td>320.768965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>158.470684</td>\n",
       "      <td>145.639000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_pred      y_real\n",
       "0 -269.240138 -258.456618\n",
       "1 -349.576199 -357.875617\n",
       "2  106.003478  108.004509\n",
       "3  -31.193701   -8.406755\n",
       "4 -240.331344 -226.748542\n",
       "5  -44.646219  -38.232029\n",
       "6    3.240374   18.147537\n",
       "7 -819.226112 -821.273651\n",
       "8  322.174534  320.768965\n",
       "9  158.470684  145.639000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Predict labels with trained model\n",
    "y_pred = reg.predict(X)\n",
    "\n",
    "# Create dataframe for printing the predictions\n",
    "df = pd.DataFrame({\"y_pred\": y_pred[:10], \"y_real\": y[:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring the model\n",
    "\n",
    "We can use these predictions to evaluate the performance of the model. That is, estimate how wrong the model is by quantifing the difference between the predicted values and the real ones. \n",
    "\n",
    "In scikit-learn we can evaluate this performance using the method `score`. Let's use this method to evaluate how well our model predicts the targets of our fake dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model R2: 0.999\n"
     ]
    }
   ],
   "source": [
    "score = reg.score(X, y)\n",
    "print(f\"Linear model R2: {np.round(score,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, linear models are evaluated by calculating $R^2$.\n",
    "\n",
    "(...) Explain $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other scoring metrics for regression problems besides $R^2$. One of this is __mean squared error__. Check out our [optional material](#Mean-squared-error) to read more about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✍️ Exercise\n",
    "\n",
    "Suppose we already have `X` and `y` defined and we want perform linear regression on our data. Why would the following code fail?\n",
    "\n",
    "```\n",
    "reg = LinearRegression()\n",
    "reg.score(X, y)\n",
    "```\n",
    "\n",
    "Can you fix it? Click the three dots to reveal the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "The code did not fit the model! For it to work it should read:\n",
    "\n",
    "```\n",
    "reg = LinearRegression()\n",
    "reg.fit(X, y)\n",
    "reg.score(X, y)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "\n",
    "As mentioned, classification models are also estimators. One of the most popular classification models is __logistic regression__\n",
    "\n",
    "(...) Explain logistic regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a fake dataset ready for classification using the `make_classification` method (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=400, n_features=100, n_informative=20, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `y` should now be a categorical variable. Let's print 10 samples of it to make sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 0 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create a `LogisticRegression` estimator (read the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)) and fit it to our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create model\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Fit model\n",
    "clf = clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✍️ Exercise\n",
    "\n",
    "Do you remember how to inspect the coefficients and intercept of the model? Try it below, and press the three dots to check your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "[[-1.37865003e-01 -2.20273104e-02 -2.39241152e-01 -2.46015623e-01\n",
      "   2.16858205e-02  3.34134331e-01  9.73462720e-02  4.68957239e-01\n",
      "  -2.61039306e-02  2.60097530e-01 -1.16922255e-01  8.29380097e-02\n",
      "   6.47792823e-02  2.51815595e-01  8.06678768e-02 -1.15678354e-01\n",
      "  -1.62860155e-02  3.04076427e-01 -9.55243706e-02  1.76554979e-01\n",
      "   2.68770910e-01  4.08755553e-01 -9.16686833e-02  2.02690284e-01\n",
      "   1.89689277e-01 -6.68554434e-02 -2.98456270e-01  5.43628947e-01\n",
      "   1.87324488e-01  1.00905626e-01 -1.77535049e-01 -5.64612899e-02\n",
      "  -3.37429083e-01 -1.15636106e-01 -6.12942018e-02  1.94713366e-01\n",
      "   1.40376760e-01 -2.42602368e-01 -1.00217142e-02 -2.05849597e-01\n",
      "  -3.19467820e-03 -1.34768011e-01 -9.70155832e-02  1.22589582e-02\n",
      "  -6.26549917e-01 -5.70595245e-01 -1.14932718e-01 -2.73770288e-01\n",
      "   1.25677528e-04  1.31212109e-02  1.54177311e-01 -2.33365126e-01\n",
      "  -9.09854209e-02  7.55769732e-02 -1.88509599e-01 -3.29841934e-01\n",
      "   6.12481338e-02 -3.27147610e-01 -2.11144886e-01  2.05836757e-01\n",
      "   1.99178019e-02 -2.38203428e-01  1.49083655e-01  1.24767070e-01\n",
      "  -2.36166986e-01  2.18618781e-01 -8.78593049e-02  1.39129048e-01\n",
      "   2.55748303e-01 -2.84696335e-03 -1.33072182e-02  5.85630033e-02\n",
      "  -1.93144127e-01  1.99019159e-01  1.75313428e-02 -4.18082180e-01\n",
      "  -9.10262641e-03  1.11632033e-01  2.34250272e-02  2.45002119e-01\n",
      "  -3.36195667e-01  6.14907090e-02 -1.38096171e-01  4.95194486e-02\n",
      "   1.94175862e-01 -6.44364418e-03  5.07273766e-02  5.06502031e-02\n",
      "  -9.52866499e-03 -9.42081810e-02 -1.43740109e-01  3.54897064e-01\n",
      "  -1.35320585e-01  1.49099197e-01  9.42566028e-02  3.15512387e-01\n",
      "   3.30221249e-02 -2.96978401e-01  3.19786546e-02 -1.75504266e-01]]\n",
      "\n",
      "Intercept:[0.48928642]\n"
     ]
    }
   ],
   "source": [
    "## Answer\n",
    "coefs = clf.coef_\n",
    "intercept = clf.intercept_\n",
    "\n",
    "print(f\"Coefficients:\\n{coefs}\\n\")\n",
    "print(f\"Intercept:{intercept}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compare the model predictions of the first 10 samples of `X` to their real labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_pred  y_real\n",
       "0       1       1\n",
       "1       0       0\n",
       "2       0       0\n",
       "3       1       1\n",
       "4       0       0\n",
       "5       1       1\n",
       "6       0       1\n",
       "7       0       0\n",
       "8       1       1\n",
       "9       1       1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict labels with trained model\n",
    "y_pred = clf.predict(X[:10])\n",
    "y_real = y[:10]\n",
    "\n",
    "# Create dataframe for printing the predictions\n",
    "df = pd.DataFrame({\"y_pred\": y_pred, \"y_real\": y_real})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic predictions\n",
    "\n",
    "Logistic Regression is a [probabilistic classifier](https://en.wikipedia.org/wiki/Probabilistic_classification), meaning it predicts a probability distribution over the classes.\n",
    "\n",
    "In _scikit-learn_ we can inspect the probabilities assigned to each class in the following manner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class 0</th>\n",
       "      <th>class 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092846</td>\n",
       "      <td>0.907154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987344</td>\n",
       "      <td>0.012656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.997656</td>\n",
       "      <td>0.002344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999740</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.324488</td>\n",
       "      <td>0.675512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.379519</td>\n",
       "      <td>0.620481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.982641</td>\n",
       "      <td>0.017359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007852</td>\n",
       "      <td>0.992148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.011529</td>\n",
       "      <td>0.988471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    class 0   class 1\n",
       "0  0.092846  0.907154\n",
       "1  0.987344  0.012656\n",
       "2  0.997656  0.002344\n",
       "3  0.999994  0.000006\n",
       "4  0.999740  0.000260\n",
       "5  0.324488  0.675512\n",
       "6  0.379519  0.620481\n",
       "7  0.982641  0.017359\n",
       "8  0.007852  0.992148\n",
       "9  0.011529  0.988471"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the probability of each class\n",
    "y_pred_proba = clf.predict_proba(X[:10])\n",
    "\n",
    "# Create dataframe for printing the predictions\n",
    "df = pd.DataFrame(y_pred_proba, columns=[\"class 0\", \"class 1\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the predictions made by `LogisticRegression` when calling `score` are evaluated by computing the __mean accuracy__ of the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "# Score predictions\n",
    "score = clf.score(X, y)\n",
    "print(f\"Mean accuracy: {np.round(score, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides scoring the model, in classification problems, it is very common to plot the __confusion matrix__ of the predictions.\n",
    "\n",
    "(...) Explain what is a confusion matrix. Paste picture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now learn how to plot the confusion matrix of the predictions of some model in scikit-learn. \n",
    "\n",
    "We will first create an imbalanced classification dataset, meaning one containing more samples from one of the classes than the other. This dataset will make the example more interesting. We can create the imbalance by setting the parameter `weights` of `make_classification`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=400, n_features=100, n_informative=20, \n",
    "    weights=[0.8, 0.2], random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create and fit a logistic regression model, and use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and fit model\n",
    "clf = LogisticRegression().fit(X, y)\n",
    "\n",
    "# Use model to make predictions\n",
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the predicted labels, we can now run this computation using the function `confusion_matrix` (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)), and display it using `ConfusionMatrixDisplay` (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "conf_matrix = confusion_matrix(y, y_pred, labels=clf.classes_)\n",
    "cm_display = ConfusionMatrixDisplay(conf_matrix).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(...) Explain output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ✍️ Exercise\n",
    "\n",
    "Read the documentation of `classification_report` [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html). Can you understand what this function does, and implement it yourself?\n",
    "\n",
    "There are other ways of scoring your model besides computing its mean accuracy. Read the documentation about scoring the [precision](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score) and the [recall](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score) of a model. \n",
    "\n",
    "Can you implement these score functions yourself? Try it below, and prress the three dots to reveal the answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8970588235294118\n",
      "Recall: 0.7625\n"
     ]
    }
   ],
   "source": [
    "# Answer\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y, y_pred)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = recall_score(y, y_pred)\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine\n",
    "\n",
    "- (...) What is SVM \n",
    "    - Can be both used for regression and classification\n",
    "    - Very common in fMRI research\n",
    "- !! Link to SVM resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train a support vector classifier using `SVC` (read the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC)). By default `SVC` uses `rbf` as its kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9875"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create model\n",
    "svc = SVC()\n",
    "\n",
    "# Fit model\n",
    "svc = svc.fit(X, y)\n",
    "\n",
    "# Score predictions\n",
    "svc.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans\n",
    "\n",
    "Unsupervised models are also estimators in scikit-learn, since they also learn from data\n",
    "\n",
    "- (...) recap of unsupervised learning:\n",
    "    - the goal is to find interesting or useful structure in the data\n",
    "    - we don't have the ground truth\n",
    "\n",
    "Clustering methods are unsupervised models. \n",
    "    - (...) explain clustering methods\n",
    "\n",
    "One popular clustering method is k-means\n",
    "    - (...) Explain how k-means work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a dataset suitable for clustering using `make_blobs` (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html#sklearn.datasets.make_blobs)) which generates Gaussian shaped blobs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y = make_blobs(\n",
    "    n_samples=400, n_features=100, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform k-means clustering by calling `KMeans` in scikit-learn (read documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)). We will pre-define $k$ to be equal to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create model\n",
    "kmeans = KMeans(n_clusters=5)\n",
    "\n",
    "# Fit model\n",
    "kmeans = kmeans.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is an unsupervised method and there is no real truth labels, we cannot compute the accuracy of the fitted model. But we can compute the average distance of the labeled example to the center of their assigned cluster using the `score` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average distance: -38848.89235461249\n"
     ]
    }
   ],
   "source": [
    "# Compute average distance\n",
    "score = kmeans.score(X, y)\n",
    "print(f\"Average distance: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to read more about the meaning behind the returned value, read [this answer](https://stackoverflow.com/questions/32370543/understanding-score-returned-by-scikit-learn-kmeans)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More importantly, we can now use our fitted model to predict to which cluster the observations belong to. Let's predict the assignment of the first 10 observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 0, 0, 4, 3, 3, 1, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict cluster label\n",
    "kmeans.predict(X[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the same number of predicted labels as the number of $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "Can you try reproducing the code above running `KMeans` with `k=3`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correct answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check your knowledge\n",
    "\n",
    "Load the ABIDE 2 dataset and:\n",
    "\n",
    "1. Use logistic regression to predict \"group\" from the ROI features.\n",
    "    - How accurate is the model?\n",
    "2. Compute the confusion matrix and inspect the proportion of false positives and false negatives.\n",
    "3. Compute the precision-recall curve.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional reading\n",
    "\n",
    "- [Choosing the right estimator](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html): A useful map to decide which estimator is best given your dataset and learning goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean squared error\n",
    "\n",
    "We can also use other metrics to score our model. The module [_sklearn.metrics_](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics) provides many different functions for doing so.\n",
    "\n",
    "One well-known metric for scoring regression models is __mean squared error__.\n",
    "\n",
    "(...) explain mean squared error.\n",
    "\n",
    "Let's compute the mean squared error of our predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 8.51\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create dataset\n",
    "X, y = make_regression(\n",
    "    n_samples=400, n_features=100, n_informative=20, noise=10, random_state=0\n",
    ")\n",
    "\n",
    "# Fit Linear Regression\n",
    "reg = LinearRegression().fit(X, y)\n",
    "\n",
    "# Predict labels with trained model\n",
    "y_pred = reg.predict(X)\n",
    "\n",
    "# Compute mean squared error\n",
    "mse = mean_squared_error(y, y_pred, squared=False)\n",
    "print(f\"Mean Squared Error: {np.round(mse, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As anticipated, the score values will not be between 0 and 1. \n",
    "\n",
    "(...) explain more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision- recall curve score\n",
    "\n",
    "(...) explain precision, recall, and the precision recall curve method for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y, y_pred)\n",
    "#print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
