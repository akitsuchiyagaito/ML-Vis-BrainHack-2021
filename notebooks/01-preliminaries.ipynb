{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Preliminaries and data\n",
    "\n",
    "Welcome to this tutorial! In this notebook we will review:\n",
    "- How this tutorial is organized, and the background knowledge you will need for it.\n",
    "- Common Python libraries for performing machine learning analyses, outlining the ones we will use in this tutorial.\n",
    "- The dataset used for the exercises.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this tutorial\n",
    "\n",
    "This short interactive tutorial will show you \n",
    "how to use the [scikit-learn](https://scikit-learn.org/) \n",
    "Python package to perform basic machine learning analysis. \n",
    "It will also cover how to visualize your results with \n",
    "the [Matplotlib](https://matplotlib.org/) \n",
    "and [seaborn](https://seaborn.pydata.org/) Python packages. \n",
    "\n",
    "## The contents\n",
    "{TO-DO: enumerate notebooks}\n",
    "\n",
    "## Assumed background knowledge\n",
    "- For this tutorial, we assume you have:\n",
    "    - Basic knowledge of Machine Learning concepts. \n",
    "    For example, you know the difference between supervised/unsupervised learning, \n",
    "    or the difference between classification, regression and clustering models.\n",
    "    - Basic experience with Python\n",
    "- We also assume that you have seen the video \n",
    "[\"A tutorial on machine learning\"](https://www.youtube.com/watch?v=pOAK6ynM11E&list=PLVso6Qs8PLCiciMyxyqxCzp38G5tEhdy6&index=6) \n",
    "by [Laura Suarez](https://twitter.com/LauraESuarez24).\n",
    "\n",
    "If you think you are lacking some of this knowledge/experience, \n",
    "we recommend the following resources to fill this gap:\n",
    "\n",
    "### ML background resources\n",
    "{TO-DO: list}\n",
    "\n",
    "### Python background resources\n",
    "\n",
    "{TO-DO: list}\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning software in Python\n",
    "\n",
    "The most well-known Python library for performing machine learning (ML) analysis is [__scikit-learn__](https://scikit-learn.org/).\n",
    "- (...) explain about the resources in scikit learn\n",
    "\n",
    "In neuroscience research, other toolboxes have been developed specifically for carrying out ML analysis on neuroimaging data. For example, [nilearn](https://nilearn.github.io/) is very popular among fMRI researchers, while [mne](https://martinos.org/mne/stable/index.html) is most known among the M/EEG community.\n",
    "\n",
    "Scikit-learn is the backbone of both _nilearn_ and _mne_, so in this tutorial we will explain how to use this more general toolbox with the hopes that learning how to use it will also come in handy when using more specific toolboxes.\n",
    "\n",
    "- (...) [explain that we will be using other software like pandas and numpy]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The datasets\n",
    "\n",
    "In each of the notebooks we will exemplify how to run ML analysis using fake data generated by _scikit-learn_, or will use well-known datasets that can be retrieved using _scikit-learn_ API. We will not be using real neuroimaging data for these purposes.\n",
    "\n",
    "However, at the end of each notebook you will find exercises where you will need to practice what you have learned using a real neuroimaging dataset. For these exercises, we will use a dataset from the [Autism Brain Imaging Data Exchange II](http://fcon_1000.projects.nitrc.org/indi/abide/abide_II.html) (ABIDE II) project. ABIDE is a long-running effort to advance understanding of autism by aggregating and sharing autism-related structural and functional imaging datasets from around the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's familiarize ourselves with this dataset. We will use [pandas](https://pandas.pydata.org/) for inspecting the data in this and the following tutorials. If you are not familiar with _pandas_ you can read their tutorial [\"10 minutes to pandas\"](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "abide_data = pd.read_csv(\"../data/abide2.tsv\", sep=\"\\t\")\n",
    "abide_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using _pandas_, we can quickly visualize that our dataset has 1004 rows and 1446 columns. Each row appears to store the information about one subject, measured in a specific neuroimaging center (endoded by the column `site`). The table provides demographic data for such participant, specifically their `age` and `sex`. \n",
    "\n",
    "Let's plot the age of the participants. Don't worry about the code that produces this plot yet. How to visualize data will be showed in [notebook 5](./05-visualization.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(abide_data[\"age\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the majority of the partipants are kids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, this demographic data will not be relevant. In our case, we are mostly interested in being able to predict whether the participant has autism or not, from their brain recordings. \n",
    "\n",
    "Thus, the column `group` encodes the variable we want to predict (1 = autism, 2 = control).\n",
    "\n",
    "(...) Explain brain recordings:\n",
    "- These dataset encodes fMRI recordings with the columns starting with `fs`. \n",
    "- What ROIs are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(...) We are lucky, because this dataset is already pretty much prepared for performing machine learning analysis with it. A dataset ready for machine learning analysis:\n",
    "- explain `X` (with samples (also called observations) and features (also called predictors)) \n",
    "    - In neuro features can represent channels, voxels, rois, etc.\n",
    "- and `y` (labels, targets)\n",
    "- explain the format of `X` {n_samples by n_features}\n",
    "    - Add image\n",
    "- In scikit-learn `X` can both be passed as a pandas dataframe or as a numpy array.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgements\n",
    "\n",
    "This tutorial is similar to, and takes inspiration from:\n",
    "- https://inria.github.io/scikit-learn-mooc/\n",
    "- https://github.com/jakevdp/sklearn_tutorial\n",
    "- https://github.com/tyarkoni/ML4PS\n",
    "- https://github.com/neurohackademy/nh2020-curriculum/blob/master/tu-machine-learning-yarkoni/01-preliminaries.ipynb\n",
    "- Link to Sina's tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
